{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import retro\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from retro import data\n",
    "import random\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "class SMBAI(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SMBAI, self).__init__()\n",
    "        self.Conv1 = nn.Conv2d(3, 9, 5, groups=3)\n",
    "        self.Conv2 = nn.Conv2d(9, 45, 5)\n",
    "        self.Conv3 = nn.Conv2d(45, 90, 5)\n",
    "        self.MaxPool = nn.MaxPool2d(16)\n",
    "        self.Lin1 = nn.Linear(16380, 5000)\n",
    "        self.Lin2 = nn.Linear(5000, 2000)\n",
    "        self.Lin3 = nn.Linear(2000, 500)\n",
    "        self.Lin4 = nn.Linear(500, 18)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.Conv1(x)\n",
    "        x = self.Conv2(x)\n",
    "        x = self.Conv3(x)\n",
    "        x = self.MaxPool(x)\n",
    "        x = x.view(-1, 16380)\n",
    "        x = self.Lin1(x)\n",
    "        x = self.Lin2(x)\n",
    "        x = self.Lin3(x)\n",
    "        x = self.Lin4(x)\n",
    "        return x\n",
    "def ChooseButton(x, epsilon):\n",
    "    if random.uniform(0, 1) <= epsilon:\n",
    "        y = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "        randb = random.randint(0, 8)\n",
    "        y[randb] = 1\n",
    "    else:\n",
    "        x = x.squeeze(0)\n",
    "        x = x.view(9, 2)\n",
    "        y = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "        z = 0\n",
    "        for button in range(len(x)):\n",
    "            y[button] = (((x[button] == float(torch.max(x[button]))).nonzero()).tolist())[0][0] \n",
    "        if y[7] == 1 and y[8] == 1: #Make sure L and R aren't both inputted\n",
    "            if torch.max(x[7]) > torch.max(x[8]):\n",
    "                 y[8] = 0\n",
    "            else:\n",
    "                y[7] = 0\n",
    "    global epsilon_min\n",
    "    global epsilon_decay\n",
    "    if epsilon > epsilon_min:\n",
    "        epsilon *= epsilon_decay\n",
    "    return y, epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'action' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-a6f5c3b3202d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0mtarget_actual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                 \u001b[0mtarget_actual\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'action' is not defined"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    env\n",
    "except NameError:\n",
    "    env = retro.make(game='SuperMarioBros-Nes', state='Level1-1')\n",
    "else:\n",
    "    env.close()\n",
    "    env = retro.make(game='SuperMarioBros-Nes', state='Level1-1')\n",
    "epsilon = 1.00\n",
    "epsilon_min = .001\n",
    "epsilon_decay = .999\n",
    "gamma = .01\n",
    "Qlog = deque(maxlen=1000)\n",
    "AI = SMBAI()\n",
    "AI = AI.cuda()\n",
    "LossF1 = nn.MSELoss()\n",
    "OptimF1 = optim.Adam(AI.parameters(), lr=.01)\n",
    "frameval = 1000\n",
    "frames = frameval\n",
    "epochs = 100\n",
    "batch_size = 100\n",
    "for x in range(epochs):\n",
    "    done = False\n",
    "    pvals = env.reset() # 224x240x3\n",
    "    pvals = torch.from_numpy(pvals)\n",
    "    pvals = pvals.view(3, 224, 240)\n",
    "    pvals = torch.tensor(pvals, dtype = torch.float32, device = 'cuda')\n",
    "    output = AI(pvals.unsqueeze(0))\n",
    "    button, epsilon = ChooseButton(output, epsilon)\n",
    "    frames = frameval\n",
    "    while not done:\n",
    "        frames = frames - 1\n",
    "        obs, rew, done, info = env.step(button)\n",
    "        Qlog.append((pvals, button, rew, obs, done))\n",
    "        reward = rew if not done else -100\n",
    "        #pvals = torch.from_numpy(obs)\n",
    "        #pvals = pvals.view(3, 224, 240)\n",
    "        #pvals = torch.LongTensor(pvals, device = 'cuda')\n",
    "        output = AI(pvals.unsqueeze(0))\n",
    "        button, epsilon = ChooseButton(output, epsilon)\n",
    "        if len(Qlog) > batch_size:\n",
    "            Qbatch = random.sample(Qlog, batch_size)\n",
    "            for qstate, qactions, qreward, qnextstate, qdone in Qbatch:\n",
    "                #qstate = torch.from_numpy(qstate)\n",
    "                qstate = torch.reshape(qstate, (3, 224, 240))\n",
    "                qstate = qstate.cuda()\n",
    "                qnextstate = torch.from_numpy(qnextstate)\n",
    "                qnextstate = torch.reshape(qnextstate, (3, 224, 240))\n",
    "                target = qreward\n",
    "                if not done:\n",
    "                    #target = (qreward + gamma * torch.max(AI(qnextstate.unsqueeze(0)).data[0]))\n",
    "                    # Find the action with the best reward given the next state\n",
    "                # Set target to be action with best reward\n",
    "                self.opt.zero_grad()\n",
    "                out = AI(Variable(torch.Tensor(qstate.unsqueeze(0))))\n",
    "                loss = LossF1(out, Variable(torch.Tensor(target_actual)))\n",
    "                LossF1.backward()\n",
    "                OptimF1.step()\n",
    "        #env.render()\n",
    "        if frames == 0:\n",
    "            done = True\n",
    "        if done:\n",
    "            print(\"episode: {}/{}, score: {}, e: {}\".format(x, epochs, reward, epsilon))\n",
    "\n",
    "torch.save(AI.state_dict(), \"./SMBAI.backup1.pth\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
